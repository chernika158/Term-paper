{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmsbB68MTOpF"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import shutil\n",
        "import posixpath\n",
        "import wfdb\n",
        "import pywt\n",
        "import seaborn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZEUvsZgRjHV"
      },
      "source": [
        "def denoise(data):\n",
        "    # Wavelet transform\n",
        "    coeffs = pywt.wavedec(data=data, wavelet='db5', level=9)\n",
        "    cA9, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
        "\n",
        "    # Threshold denoising\n",
        "    threshold = (np.median(np.abs(cD1)) / 0.6745) * (np.sqrt(2 * np.log(len(cD1))))\n",
        "    cD1.fill(0)\n",
        "    cD2.fill(0)\n",
        "    for i in range(1, len(coeffs) - 2):\n",
        "        coeffs[i] = pywt.threshold(coeffs[i], threshold)\n",
        "\n",
        "    # Wavelet inverse transform, obtain the denoised signal\n",
        "    rdata = pywt.waverec(coeffs=coeffs, wavelet='db5')\n",
        "    return rdata\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muOWqNM_Rmlo"
      },
      "source": [
        "# Read ECG data and corresponding labels,\n",
        "# and perform wavelet denoising on the data\n",
        "def getDataSet(number, X_data, Y_data):\n",
        "    ecgClassSet = ['N', 'A', 'V', 'L', 'R']\n",
        "\n",
        "    # Reading ECG data records\n",
        "    print(\"Being read\" + number + \" No. ECG data\")\n",
        "    record = wfdb.rdrecord('/content/drive/MyDrive/Colab Notebooks/ECG_rec/ecg_data/' + number, channel_names=['MLII'])\n",
        "    data = record.p_signal.flatten()\n",
        "    rdata = denoise(data=data)\n",
        "\n",
        "    # Obtain the position of the R wave and the corresponding label in the ECG data record\n",
        "    annotation = wfdb.rdann('/content/drive/MyDrive/Colab Notebooks/ECG_rec/ecg_data/' + number, 'atr')\n",
        "    Rlocation = annotation.sample\n",
        "    Rclass = annotation.symbol\n",
        "\n",
        "    # Removal of before and after unstable data\n",
        "    start = 10\n",
        "    end = 5\n",
        "    i = start\n",
        "    j = len(annotation.symbol) - end\n",
        "\n",
        "    # Because only the five NAVLR ECG types are selected, those data with specific labels needed for that record are selected, and the rest of the labeled points are discarded\n",
        "    # X_data intercepts data points with a length of 300 before and after the R wave\n",
        "    # Y_data converts NAVLR to 01234 in order\n",
        "    while i < j:\n",
        "        try:\n",
        "            lable = ecgClassSet.index(Rclass[i])\n",
        "            x_train = rdata[Rlocation[i] - 99:Rlocation[i] + 201]\n",
        "            X_data.append(x_train)\n",
        "            Y_data.append(lable)\n",
        "            i += 1\n",
        "        except ValueError:\n",
        "            i += 1\n",
        "    return\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srGkaqVsSFqV"
      },
      "source": [
        "# Load the dataset and pre-process it\n",
        "def loadData():\n",
        "    numberSet = ['100', '101', '103', '105', '106', '107', '108', '109', '111', '112', '113', '114', '115',\n",
        "                 '116', '117', '119', '121', '122', '123', '124', '200', '201', '202', '203', '205', '208',\n",
        "                 '210', '212', '213', '214', '215', '217', '219', '220', '221', '222', '223', '228', '230',\n",
        "                 '231', '232', '233', '234']\n",
        "    dataSet = []\n",
        "    lableSet = []\n",
        "    for n in numberSet:\n",
        "        getDataSet(n, dataSet, lableSet)\n",
        "\n",
        "    # Turning numpy arrays, breaking the order\n",
        "    dataSet = np.array(dataSet).reshape(-1, 300)\n",
        "    lableSet = np.array(lableSet).reshape(-1, 1)\n",
        "    train_ds = np.hstack((dataSet, lableSet))\n",
        "    np.random.shuffle(train_ds)\n",
        "\n",
        "    # Data sets and their label set\n",
        "    X = train_ds[:, :300].reshape(-1, 300, 1)\n",
        "    Y = train_ds[:, 300]\n",
        "\n",
        "    # Test sets and their tag sets\n",
        "    shuffle_index = np.random.permutation(len(X))\n",
        "    test_length = int(RATIO * len(shuffle_index))\n",
        "    test_index = shuffle_index[:test_length]\n",
        "    train_index = shuffle_index[test_length:]\n",
        "    X_test, Y_test = X[test_index], Y[test_index]\n",
        "    X_train, Y_train = X[train_index], Y[train_index]\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nDhJwcDSL_Y"
      },
      "source": [
        "# Building CNN models\n",
        "def buildModel():\n",
        "    newModel = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(300, 1)),\n",
        "        # First convolutional layer, 4 21x1 convolutional kernels\n",
        "        tf.keras.layers.Conv1D(filters=4, kernel_size=21, strides=1, padding='SAME', activation='relu'),\n",
        "        # First pooling layer, maximum pooling, four 3x1 convolutional kernels, step size 2\n",
        "        tf.keras.layers.MaxPool1D(pool_size=3, strides=2, padding='SAME'),\n",
        "        # Second convolutional layer, 16 23x1 convolutional kernels\n",
        "        tf.keras.layers.Conv1D(filters=16, kernel_size=23, strides=1, padding='SAME', activation='relu'),\n",
        "        # Second pooling layer, maximum pooling, four 3x1 convolutional kernels, step size 2\n",
        "        tf.keras.layers.MaxPool1D(pool_size=3, strides=2, padding='SAME'),\n",
        "        # Third convolutional layer, 32 25x1 convolutional kernels\n",
        "        tf.keras.layers.Conv1D(filters=32, kernel_size=25, strides=1, padding='SAME', activation='relu'),\n",
        "        # Third pooling layer, average pooling, four 3x1 convolutional kernels, step size 2\n",
        "        tf.keras.layers.AvgPool1D(pool_size=3, strides=2, padding='SAME'),\n",
        "        # Fourth convolutional layer, 64 27x1 convolutional kernels\n",
        "        tf.keras.layers.Conv1D(filters=64, kernel_size=27, strides=1, padding='SAME', activation='relu'),\n",
        "        # Flattening layer, convenient for full connection layer processing\n",
        "        tf.keras.layers.Flatten(),\n",
        "        # Fully connected layer, 128 nodes\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        # Dropout Layer,dropout = 0.2\n",
        "        tf.keras.layers.Dropout(rate=0.2),\n",
        "        # Fully connected layer, 5 nodes\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "    return newModel\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rESjKKOxSR9Q"
      },
      "source": [
        "# Confusion Matrix\n",
        "def plotHeatMap(Y_test, Y_pred):\n",
        "    con_mat = confusion_matrix(Y_test, Y_pred)\n",
        "    # Normalization\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    seaborn.heatmap(con_mat, annot=True, fmt='.20g', cmap='Blues')\n",
        "    plt.ylim(0, 5)\n",
        "    plt.xlabel('Predicted labels')\n",
        "    plt.ylabel('True labels')\n",
        "    plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Cc3dt9STpa",
        "outputId": "cf3c2381-9a37-4d7e-8b5d-18ffe12da336"
      },
      "source": [
        "project_path = \"D:\\\\python\\\\mit-bih_ecg_recognition\\\\\"\n",
        "log_dir = project_path + \"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "model_path = project_path + \"ecg_model.h5\"\n",
        "\n",
        "RATIO = 0.3\n",
        "\n",
        "# X_train,Y_train are all datasets and label sets\n",
        "# X_test,Y_test are the split test set and label set\n",
        "X_train, Y_train, X_test, Y_test = loadData()\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    model = tf.keras.models.load_model(filepath=model_path)\n",
        "else:\n",
        "    model = buildModel()\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    model.fit(X_train, Y_train, epochs=30,\n",
        "              batch_size=128,\n",
        "              validation_split=RATIO,\n",
        "              callbacks=[tensorboard_callback])\n",
        "    model.save(filepath=model_path)\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)\n",
        "plotHeatMap(Y_test, Y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Being read100 No. ECG data\n",
            "Being read101 No. ECG data\n",
            "Being read103 No. ECG data\n",
            "Being read105 No. ECG data\n",
            "Being read106 No. ECG data\n",
            "Being read107 No. ECG data\n",
            "Being read108 No. ECG data\n",
            "Being read109 No. ECG data\n",
            "Being read111 No. ECG data\n",
            "Being read112 No. ECG data\n",
            "Being read113 No. ECG data\n",
            "Being read114 No. ECG data\n",
            "Being read115 No. ECG data\n",
            "Being read116 No. ECG data\n",
            "Being read117 No. ECG data\n",
            "Being read119 No. ECG data\n",
            "Being read121 No. ECG data\n",
            "Being read122 No. ECG data\n",
            "Being read123 No. ECG data\n",
            "Being read124 No. ECG data\n",
            "Being read200 No. ECG data\n",
            "Being read201 No. ECG data\n",
            "Being read202 No. ECG data\n",
            "Being read203 No. ECG data\n",
            "Being read205 No. ECG data\n",
            "Being read208 No. ECG data\n",
            "Being read210 No. ECG data\n",
            "Being read212 No. ECG data\n",
            "Being read213 No. ECG data\n",
            "Being read214 No. ECG data\n",
            "Being read215 No. ECG data\n",
            "Being read217 No. ECG data\n",
            "Being read219 No. ECG data\n",
            "Being read220 No. ECG data\n",
            "Being read221 No. ECG data\n",
            "Being read222 No. ECG data\n",
            "Being read223 No. ECG data\n",
            "Being read228 No. ECG data\n",
            "Being read230 No. ECG data\n",
            "Being read231 No. ECG data\n",
            "Being read232 No. ECG data\n",
            "Being read233 No. ECG data\n",
            "Being read234 No. ECG data\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 300, 4)            88        \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 150, 4)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 150, 16)           1488      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 75, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 75, 32)            12832     \n",
            "_________________________________________________________________\n",
            "average_pooling1d (AveragePo (None, 38, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 38, 64)            55360     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2432)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               311424    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 381,837\n",
            "Trainable params: 381,837\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.2470 - accuracy: 0.9335 - val_loss: 0.0750 - val_accuracy: 0.9848\n",
            "Epoch 2/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0627 - accuracy: 0.9840 - val_loss: 0.0418 - val_accuracy: 0.9891\n",
            "Epoch 3/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0437 - accuracy: 0.9879 - val_loss: 0.0333 - val_accuracy: 0.9909\n",
            "Epoch 4/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.0367 - accuracy: 0.9899 - val_loss: 0.0284 - val_accuracy: 0.9925\n",
            "Epoch 5/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0306 - accuracy: 0.9909 - val_loss: 0.0347 - val_accuracy: 0.9914\n",
            "Epoch 6/30\n",
            "353/353 [==============================] - 45s 128ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0287 - val_accuracy: 0.9927\n",
            "Epoch 7/30\n",
            "353/353 [==============================] - 44s 125ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0336 - val_accuracy: 0.9911\n",
            "Epoch 8/30\n",
            "353/353 [==============================] - 45s 126ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0246 - val_accuracy: 0.9946\n",
            "Epoch 9/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.0271 - val_accuracy: 0.9939\n",
            "Epoch 10/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0264 - val_accuracy: 0.9946\n",
            "Epoch 11/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.0261 - val_accuracy: 0.9941\n",
            "Epoch 12/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.0297 - val_accuracy: 0.9926\n",
            "Epoch 13/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.0297 - val_accuracy: 0.9927\n",
            "Epoch 14/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0283 - val_accuracy: 0.9950\n",
            "Epoch 15/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0362 - val_accuracy: 0.9928\n",
            "Epoch 16/30\n",
            "353/353 [==============================] - 45s 126ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0291 - val_accuracy: 0.9938\n",
            "Epoch 17/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0299 - val_accuracy: 0.9932\n",
            "Epoch 18/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0323 - val_accuracy: 0.9940\n",
            "Epoch 19/30\n",
            "353/353 [==============================] - 45s 126ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0299 - val_accuracy: 0.9942\n",
            "Epoch 20/30\n",
            "353/353 [==============================] - 45s 126ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0342 - val_accuracy: 0.9934\n",
            "Epoch 21/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0324 - val_accuracy: 0.9940\n",
            "Epoch 22/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0394 - val_accuracy: 0.9948\n",
            "Epoch 23/30\n",
            "353/353 [==============================] - 45s 127ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0354 - val_accuracy: 0.9943\n",
            "Epoch 24/30\n",
            "353/353 [==============================] - 44s 124ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0437 - val_accuracy: 0.9941\n",
            "Epoch 25/30\n",
            "194/353 [===============>..............] - ETA: 17s - loss: 0.0125 - accuracy: 0.9966"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn2N8UDTTer6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}